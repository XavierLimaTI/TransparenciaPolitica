# Pol√≠tica Transparente Brasil

[![CI](https://github.com/XavierLimaTI/TransparenciaPolitica/actions/workflows/ci.yml/badge.svg)](https://github.com/XavierLimaTI/TransparenciaPolitica/actions/workflows/ci.yml)
[![Codecov](https://codecov.io/gh/XavierLimaTI/TransparenciaPolitica/branch/main/graph/badge.svg?token=)](https://codecov.io/gh/XavierLimaTI/TransparenciaPolitica)
[![Node.js Version](https://img.shields.io/badge/node-%3E%3D18-brightgreen)](https://nodejs.org/)

## Descri√ß√£o

Plataforma web inovadora dedicada √† transpar√™ncia pol√≠tica brasileira, permitindo que eleitores consultem informa√ß√µes detalhadas sobre candidatos, seus votos em mat√©rias importantes da C√¢mara e Senado, e tomem decis√µes conscientes para as elei√ß√µes de 2026.

<!-- CI trigger: update README to re-run CI smoke -->

## Status do Projeto (resumo r√°pido)

- Branch atual: `infra/add-s3-lifecycle-and-secrets-docs`
- √öltima atualiza√ß√£o: 08/10/2025
- Progresso estimado: 65% completo

Principais entregas j√° realizadas:

- Fase 1 (MVP): conclu√≠da ‚Äî UI, busca, perfis, vota√ß√µes e visualiza√ß√µes implementadas.
- Ingest√£o local de dados: scripts e fixtures inclu√≠dos; `resources/data/ingested/despesas.json` dispon√≠vel para desenvolvimento.
- Auto-load de dados locais: `main.js` agora detecta `resources/data/ingested/despesas.json` e injeta os dados no app sem necessidade de `PORTAL_API_KEY`.
- Proxy de desenvolvimento + webhook-resync + metrics exporter: servidores auxiliares implementados e testados localmente.

Itens pendentes (Fase 2 - Integra√ß√£o com Dados Reais):

- Integra√ß√£o completa com o Portal da Transpar√™ncia (requer `PORTAL_API_KEY`)
- Workflow mensal: ajustar para upload-artifact por padr√£o e tornar S3 opcional (pendente)
- Validar e documentar procedimento para resync mensal e alertas/monitoramento

Pr√≥ximos passos recomendados (curto prazo):

1. Escolher se quer armazenar datasets mensais em S3 (requer credenciais) ou manter artifacts do GitHub Actions. Se optar por S3, eu posso ajustar o workflow e aplicar o Terraform opcional.
2. Executar testes de integra√ß√£o com `PORTAL_API_KEY` quando dispon√≠vel.
3. Documentar plano de manuten√ß√£o de dados (retention policy / lifecycle) e poss√≠veis custos.

## Publica√ß√£o autom√°tica dos dados ingeridos (GitHub Pages)

Para evitar custos com infraestrutura externa voc√™ pode usar o GitHub Pages para hospedar os JSONs gerados pelo pipeline de ingest√£o. Os dados publicados ficam dispon√≠veis publicamente em uma URL est√°tica e o frontend pode consumi-los diretamente.

- URL p√∫blica (padr√£o):

  https://<OWNER>.github.io/<REPO>/data/

  Exemplo para este reposit√≥rio:

  https://XavierLimaTI.github.io/TransparenciaPolitica/data/

- Como o app usa essa URL:

  1. O pipeline de ingest gera `resources/data` contendo os arquivos JSON e `manifest.json`.
  2. O workflow `publish-gh-pages.yml` copia `resources/data` para a branch `gh-pages` e publica o conte√∫do em `/data/`.
  3. O frontend pode apontar para `https://<OWNER>.github.io/<REPO>/data/manifest.json` para localizar os arquivos ingeridos.

- Automatizando atualiza√ß√µes (op√ß√µes):

  1. Agendamento mensal (recomendado para produ√ß√£o): j√° existe o workflow `monthly-download.yml` que roda no dia 1 de cada m√™s. Ele baixa, gera metadados e pode enviar artifacts ou fazer upload opcional para S3/GCS.
  2. Agendamento di√°rio/weekly (para ambientes de teste ou atualiza√ß√µes frequentes): adicione um workflow agendado para reexecutar o pipeline de ingest e publicar em GitHub Pages (o reposit√≥rio j√° cont√©m um workflow de publica√ß√£o manual `publish-gh-pages.yml`).
  3. Dispatch manual: voc√™ pode disparar `publish-gh-pages.yml` ou o novo workflow agendado manualmente via Actions ‚Üí Run workflow.

- Permiss√µes necess√°rias:

  - Para que a publica√ß√£o autom√°tica para `gh-pages` funcione o token usado pelo workflow precisa de permiss√£o de escrita (Settings ‚Üí Actions ‚Üí General ‚Üí Workflow permissions ‚Üí "Read and write permissions"). O workflow j√° detecta e avisa caso n√£o tenha permiss√£o.

- Como reexecutar localmente (PowerShell):

```powershell
# executar downloader + ingest localmente
$env:PORTAL_API_KEY = 'SUA_CHAVE_AQUI'

# baixar m√™s anterior (exemplo)
node scripts/download_portal_monthly.js --start=$(Get-Date -Day 1).AddMonths(-1).ToString('yyyy-MM-01') --end=$(Get-Date -Day 1).AddMonths(-1).ToString('yyyy-MM-01') --type=despesas --extract

# gerar ingest
node scripts/ingest-datasets.js || npm run ingest

# copiar para a pasta de publica√ß√£o local (opcional)
# cp -r resources/data gh-pages-temp/data
# abra a URL do GitHub Pages quando publicado: https://<OWNER>.github.io/<REPO>/data/
```

Se quiser que eu adicione um workflow agendado di√°rio/weekly que execute o pipeline de ingest e publique automaticamente para o GitHub Pages, eu j√° criei um workflow de exemplo no reposit√≥rio: `.github/workflows/scheduled-ingest-publish.yml`. Ele roda por schedule (di√°rio/weekly/monthly) e tamb√©m permite `workflow_dispatch` para disparo manual.

Como reproduzir o ambiente de desenvolvimento e testes r√°pidos:

```powershell
# instalar depend√™ncias (se necess√°rio)
npm install

# servidor est√°tico simples (usa Python embutido)
npm run dev

# servidor http (alternativa via npm)
npm run start:npm

# iniciar proxy de desenvolvimento (opcional)
npm run start-proxy

# iniciar collector de m√©tricas local
npm run start:metrics

# rodar smoke e2e (proxy + servidor est√°tico + checagens b√°sicas)
npm run smoke:e2e

# rodar su√≠te r√°pida de smoke tests (CSV parsing, API quick checks)
npm run test:smoke

# rodar todos os testes unit√°rios (Jest)
npm test
```

Se quiser que eu fa√ßa alguma dessas tarefas agora (ex.: ajustar workflow para artifacts-only, aplicar Terraform example, ou rodar testes contra o Portal ao fornecer `PORTAL_API_KEY`), diga qual op√ß√£o prefere.

## HOWTO r√°pido ‚Äî baixar e ingerir dados do Portal (local)

Se voc√™ quiser executar o downloader mensal e ingerir os CSVs localmente para desenvolvimento, siga estes passos (PowerShell):

```powershell
# (1) Defina a vari√°vel de ambiente com sua chave do Portal (opcional ‚Äî sem chave o downloader far√° check e pode pular).
$env:PORTAL_API_KEY = 'SUA_CHAVE_AQUI'

# (2) Baixe arquivos mensais (ex.: 20250501). Use --extract para extrair os zips localmente
npm run download:portal-monthly -- --from=20250501 --to=20250501 --extract

# (3) Ingerir os CSVs em JSON e atualizar o manifest
npm run ingest

# (4) Inicie o servidor est√°tico e abra o app
npm run start:npm

# (5) Abra http://127.0.0.1:8000 e use o footer "Carregar √∫ltimos N meses" para carregar os dados locais
```

Veja tamb√©m `infra/github-secrets.md` para instru√ß√µes sobre onde guardar segredos e como configurar o CI para uploads S3 opcionais.

## Funcionalidades Principais

### üîç Sistema de Busca Avan√ßada


### üë• Perfil de Candidatos


### üó≥Ô∏è Vota√ß√µes Detalhadas


### üìä Dashboard Interativo


## Tecnologias Utilizadas

### Frontend
- **Anime.js** - Anima√ß√µes suaves
- **Font Awesome** - √çcones vetoriais


### Design
- **Cores inspiradas na bandeira brasileira**
- **Tipografia elegante**: Playfair Display + Inter
- **Design responsivo** - Mobile-first
- **Anima√ß√µes sutis** - Melhor UX

## Estrutura do Projeto

```text
/
‚îú‚îÄ‚îÄ index.html          # P√°gina inicial com dashboard
‚îú‚îÄ‚îÄ candidatos.html     # P√°gina de candidatos com filtros
‚îú‚îÄ‚îÄ votacoes.html       # P√°gina de vota√ß√µes e an√°lises
‚îú‚îÄ‚îÄ sobre.html          # Sobre o projeto e contato
‚îú‚îÄ‚îÄ main.js            # JavaScript principal com todas as funcionalidades
‚îú‚îÄ‚îÄ resources/         # Imagens e assets
‚îÇ   ‚îú‚îÄ‚îÄ hero-bg.png           # Background hero
‚îÇ   ‚îî‚îÄ‚îÄ politician-avatars.png # Avatares dos candidatos
‚îú‚îÄ‚îÄ design.md          # Documenta√ß√£o do design
‚îú‚îÄ‚îÄ interaction.md     # Documenta√ß√£o das intera√ß√µes
‚îú‚îÄ‚îÄ outline.md         # Estrutura do projeto
‚îî‚îÄ‚îÄ README.md          # Este arquivo
```


## Funcionalidades Implementadas

### ‚úÖ Sistema de Busca
- Busca textual em tempo real
- Filtros m√∫ltiplos combin√°veis
- Ordena√ß√£o por diferentes crit√©rios
- Contadores de resultados


### ‚úÖ Perfil de Candidatos
- Cards informativos com hover effects
- Sistema de favoritos (localStorage)
- Modal detalhado com hist√≥rico completo
- Classifica√ß√£o por ideologia e partido


### ‚úÖ Vota√ß√µes
- Timeline cronol√≥gica
- Resultados por candidato
- Visualiza√ß√£o de import√¢ncia
- An√°lises contextuais


### ‚úÖ Visualiza√ß√µes de Dados
- Gr√°ficos de pizza (distribui√ß√£o por partido)
- Gr√°ficos de barras (resultados de vota√ß√µes)
- Gr√°ficos de linha (tend√™ncias temporais)
- Estat√≠sticas em tempo real

### ‚úÖ Design Responsivo

- Layout mobile-first
- Breakpoints otimizados
- Navega√ß√£o adaptativa
- Touch-friendly interface

## Como Usar

1. **Buscar Candidatos**: Use a barra de pesquisa principal ou acesse a p√°gina de candidatos para filtros avan√ßados
2. **Explorar Vota√ß√µes**: Veja as vota√ß√µes recentes e como cada candidato se posicionou
3. **Analisar Dados**: Explore os gr√°ficos interativos e estat√≠sticas
4. **Favoritar**: Marque candidatos para acompanhar (os dados s√£o salvos localmente)

## Proxy de Desenvolvimento (local)

Para rodar o proxy local recomendado (oferece rotas administrativas e fallback):

```powershell
npm install
npm run start-proxy
```

Se preferir uma alternativa sem depend√™ncias, h√° um proxy leve em `server/proxy-light.js` que pode ser executado com:

```powershell
node server/proxy-light.js
```

Nota sobre preview est√°tico
--------------------------

Ao executar `npm run build` o processo agora gera um arquivo adicional `dist/datasets-index` (sem extens√£o). O frontend tenta primeiro `/datasets-index` durante a inicializa√ß√£o ‚Äî essa rota √© normalmente fornecida pelo proxy de desenvolvimento. O arquivo `dist/datasets-index` existe para que previews est√°ticos (por exemplo com `npx http-server ./dist -p 8001`) tamb√©m possam exibir o √≠ndice de datasets sem erro 404.

Se voc√™ prefere comportamento din√¢mico (ex.: fallback para S3 ou rota administrativa), use o proxy (`npm run start-proxy` ou `node server/proxy-light.js`).

## Dados de Demonstra√ß√£o

O projeto inclui dados simulados de:
- **Projetos e promessas** de campanha
## Demo r√°pido & PR

Se quiser testar rapidamente o fluxo de ingest√£o local sem fornecer `PORTAL_API_KEY`, h√° um demo pronto neste branch:

- Branch: `feat/demo-loader`
- Pull request aberto: https://github.com/XavierLimaTI/TransparenciaPolitica/pull/18

Passos r√°pidos:

1. Na raiz do reposit√≥rio execute:

```powershell
npx http-server -c-1 -p 8000
Start-Process http://127.0.0.1:8000
```

2. Abra http://127.0.0.1:8000 no navegador e clique no bot√£o "Carregar demo (despesas)".

3. Para validar automaticamente, execute o teste Playwright previsto no branch:

```powershell
npx playwright test scripts/playwright/load-demo.spec.js
```

Notas:

- O demo carrega `resources/data/despesas.json` e dispara o evento `localDespesasUsed` para integrar os dados √† UI.
- Arquivos placeholder foram movidos (ou podem ser movidos) para `resources/data/samples/` para deixar claro que s√£o exemplos locais.

## Caracter√≠sticas T√©cnicas

### Performance
- Carregamento otimizado de imagens
- JavaScript modular e organizado
- CSS minificado via CDN
- Anima√ß√µes otimizadas para performance

### Acessibilidade
- Contraste de cores adequado
- Fontes leg√≠veis e tamanhos apropriados
- Estrutura sem√¢ntica HTML5
- Navega√ß√£o por teclado

### SEO
- Meta tags otimizadas
- Estrutura sem√¢ntica
- URLs amig√°veis
- Descri√ß√µes relevantes

## Pr√≥ximas Etapas (Roadmap)

### Fase 1 - MVP Completo ‚úÖ
- [x] Estrutura b√°sica do webapp
- [x] Sistema de busca e filtros
- [x] Perfis de candidatos
- [x] P√°gina de vota√ß√µes
- [x] Visualiza√ß√µes de dados

### Fase 2 - Integra√ß√£o com Dados Reais
- [ ] Integra√ß√£o com APIs oficiais do Congresso
- [ ] Atualiza√ß√£o autom√°tica de dados
- [ ] Sistema de cache para performance
- [ ] Webhooks para atualiza√ß√µes em tempo real

### Fase 3 - Funcionalidades Avan√ßadas
- [ ] Sistema de alertas e notifica√ß√µes
- [ ] Compara√ß√£o lado a lado de candidatos
- [ ] An√°lises preditivas
- [ ] Gamifica√ß√£o para engajamento

### Fase 4 - Comunidade e Colabora√ß√£o
- [ ] Sistema de avalia√ß√£o de candidatos
- [ ] Coment√°rios e discuss√µes
- [ ] Compartilhamento em redes sociais
- [ ] API p√∫blica para desenvolvedores

## Contribuindo

Este √© um projeto de c√≥digo aberto dedicado √† transpar√™ncia pol√≠tica no Brasil. Contribui√ß√µes s√£o bem-vindas!

### Como Contribuir
1. Fa√ßa um fork do projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

### Tipos de Contribui√ß√£o
- üêõ Corre√ß√£o de bugs
- ‚ú® Novas funcionalidades
- üìö Documenta√ß√£o
- üé® Melhorias de design
- üìä An√°lises de dados

## Testes de Integra√ß√£o (APIs reais)

H√° alguns scripts de teste r√°pidos que executam chamadas √†s APIs p√∫blicas (C√¢mara, Portal da Transpar√™ncia). Para facilitar, existe o script npm `test:integration` que roda os checks conhecidos.

## Integra√ß√£o cont√≠nua (GitHub Actions)

Este reposit√≥rio inclui um workflow de CI em `.github/workflows/ci.yml` que executa os testes unit√°rios em pushes e pull requests para `main`.

Al√©m disso existe um job de integra√ß√£o "live" que roda verifica√ß√µes contra APIs reais. Por seguran√ßa este job s√≥ √© executado automaticamente se o segredo `PORTAL_API_KEY` estiver definido no reposit√≥rio, ou pode ser disparado manualmente via a aba Actions > CI > Run workflow.

Como configurar os segredos usados pelo workflow:

- `PORTAL_API_KEY` ‚Äî chave de acesso ao Portal da Transpar√™ncia. Se definida no reposit√≥rio, o job de integra√ß√£o ser√° executado automaticamente ap√≥s os testes unit√°rios.
- `PROXY_ADMIN_TOKEN` ‚Äî token opcional usado pelo runner se o proxy exigir autentica√ß√£o administrativa.

### Upload opcional para S3 (dados mensais)

O workflow mensal (`.github/workflows/monthly-download.yml`) agora gera checksums SHA256 e um arquivo `metadata.json` dentro do diret√≥rio do dataset (por exemplo `resources/data/despesas/metadata.json`).

Se voc√™ quiser armazenar os datasets mensalmente em um bucket S3, adicione os seguintes secrets no reposit√≥rio (Settings ‚Üí Secrets and variables ‚Üí Actions):

- `AWS_ACCESS_KEY_ID`
- `AWS_SECRET_ACCESS_KEY`
- `S3_BUCKET` (nome do bucket, ex.: `meu-bucket-dados`)
- `AWS_REGION` (opcional, ex.: `sa-east-1`)

Quando esses secrets estiverem presentes, o workflow far√° upload recursivo do diret√≥rio `resources/data/despesas/` para `s3://<S3_BUCKET>/datasets/<YYYY-MM-DD>/` (onde `<YYYY-MM-DD>` √© o m√™s processado). Se os secrets n√£o estiverem definidos, o workflow mant√©m o comportamento anterior e envia os arquivos como artifact do GitHub Actions.

Formato do `metadata.json` gerado:

```json
{
  "month": "2025-09-01",
  "type": "despesas",
  "files": [
    { "name": "20250901_despesas.zip", "path": "resources/data/despesas/20250901_despesas.zip", "sha256": "...", "size": 123456 }
  ],
  "runner": "ubuntu-latest",
  "timestamp": 1693526400
}
```

Como testar o workflow manualmente:

1. V√° em Actions ‚Üí Monthly Portal Download ‚Üí Run workflow (workflow_dispatch).
2. Se quiser testar upload para S3, adicione temporariamente os secrets citados acima no reposit√≥rio (ou utilize um bucket de teste).
3. Inspecione os artefatos (se n√£o houver S3) ou verifique o bucket S3 para o prefixo `datasets/<YYYY-MM-DD>/`.

Observa√ß√£o de seguran√ßa: prefira criar um usu√°rio IAM com permiss√µes restritas ao bucket (s3:PutObject, s3:PutObjectAcl, s3:ListBucket) e prazo de validade curto para chaves de teste.

### Deduplica√ß√£o e √≠ndice central (index.json)

O workflow mensal agora tenta evitar uploads duplicados. Antes de enviar o dataset ele verifica se o arquivo `despesas_<YYYY-MM-DD>.tar.gz` j√° existe em `s3://<S3_BUCKET>/datasets/<YYYY-MM-DD>/`. Se o arquivo j√° existir, o workflow pula o upload recursivo do diret√≥rio e n√£o sobrescreve o objeto existente.

Al√©m disso, o workflow atualiza um arquivo central `datasets/index.json` no bucket contendo um √≠ndice com metadados (m√™s, arquivos, checksums, tamanhos). Esse √≠ndice √© √∫til para consultas e para checar quais meses j√° foram processados.

Como for√ßar reupload ou atualizar um m√™s existente:

1. Acesse o bucket S3 e remova o objeto `s3://<S3_BUCKET>/datasets/<YYYY-MM-DD>/despesas_<YYYY-MM-DD>.tar.gz` (ou renomeie-o).
2. Reexecute o workflow (Actions ‚Üí Monthly Portal Download ‚Üí Run workflow). O workflow detectar√° a aus√™ncia do arquivo e far√° upload do dataset e do archive.

Observa√ß√£o: o passo de atualiza√ß√£o do `index.json` usa `aws s3 cp` para baixar/enviar o arquivo e substitui a entrada do m√™s no √≠ndice.

## Servi√ßos auxiliares locais

1. Metrics exporter (Prometheus style)

Start local metrics exporter to collect simple counters:

```powershell
npm run start:metrics
# or: node tools/metrics-exporter.js
```

It exposes `/metrics` and a simple JSON endpoint `/increment` that accepts `{ "metric": "monthly_success", "value": 1 }`.

2. Webhook resync

Start the webhook consumer which listens on port 3002 by default:

```powershell
npm run start:webhook-resync
# or: node server/webhook-resync.js
```

POST `{ "start": "2025-09-01" }` to `/resync` to trigger a downloader run for that month.

3. Proxy endpoint for datasets index

During local development the proxy exposes `/datasets-index` which will return a local `resources/data/despesas/index.json` or `resources/data/index.json` if present. If not present and `S3_BUCKET` is defined in environment, the proxy will attempt to fetch `s3://<S3_BUCKET>/datasets/index.json` via AWS CLI.

4. Terraform lifecycle example

See `infra/terraform-s3-lifecycle/README.md` for a simple Terraform module that applies lifecycle rules to the `datasets/` prefix.

## M√©tricas (opcional)

O workflow pode enviar m√©tricas para um collector simples. Para usar:

1. Rode localmente `npm run start:metrics` para iniciar o collector (porta 9101 por padr√£o).
2. Adicione um secret chamado `METRICS_URL` com o valor `http://<host>:9101` (ou um endpoint p√∫blico).
3. O workflow `monthly-download.yml` enviar√° POSTs para `${METRICS_URL}/increment` com JSON `{ "metric": "monthly_success", "value": 1 }` ou `{ "metric": "monthly_failed", "value": 1 }` conforme o caso.




Passos para adicionar segredos (no GitHub):

### Tornar o job "SQLite CI" obrigat√≥rio em PRs (opcional)

O workflow `SQLite CI (optional)` agora pode ser executado em `pull_request` (al√©m de `push`) quando o secret `ENABLE_SQLITE_CI` estiver definido como `true` ou se for disparado manualmente. Se voc√™ quiser que este job seja um check obrigat√≥rio em todas as Pull Requests do branch `main`, siga estes passos:

1. V√° em Settings ‚Üí Branches ‚Üí Branch protection rules.
2. Clique em "Add rule" ou edite a regra para o branch `main`.
3. Marque "Require status checks to pass before merging".
4. Na lista "Status checks to select", escolha o check correspondente ao job (ex.: `sqlite-ci` ou o nome exato mostrado nas Actions). Se o nome n√£o aparecer imediatamente, fa√ßa um Run workflow para que o check seja registrado.
5. Salve a regra. A partir de ent√£o, Pull Requests para `main` s√≥ poder√£o ser mescladas se esse check passar.

Nota: tornar um job nativo e de build nativo obrigat√≥rio pode aumentar a fric√ß√£o em PRs (compila√ß√µes nativas falham em runners sem toolchain). Recomendo habilitar essa prote√ß√£o apenas depois de validar o job algumas vezes no CI.


1. V√° no reposit√≥rio GitHub > Settings > Secrets and variables > Actions > New repository secret.
2. Adicione `PORTAL_API_KEY` com o valor da sua chave.
3. (Opcional) Adicione `PROXY_ADMIN_TOKEN` se voc√™ usa um token para endpoints administrativos.

Executar o job de integra√ß√£o manualmente:

1. Acesse Actions > CI > Run workflow.
2. Selecione branch `main` e clique em Run workflow.

Observa√ß√£o: o job de integra√ß√£o usa `npm run test:integration`. No workflow atual o passo √© executado com `|| true` para evitar que falhas de integra√ß√£o bloqueiem o pipeline principal ‚Äî se preferir que falhas de integra√ß√£o falhem o workflow, pe√ßa que eu remova o `|| true`.


## Habilitar testes com SQLite no CI (opcional)

Este reposit√≥rio inclui um workflow opcional (`.github/workflows/sqlite-ci.yml`) que compila e executa os testes usando `better-sqlite3` (m√≥dulo nativo). Por motivos de compatibilidade e build, esse job √© opcional e pode ser executado manualmente antes de torn√°-lo obrigat√≥rio.

Passos r√°pidos para habilitar:

1. V√° em Settings ‚Üí Secrets and variables ‚Üí Actions no GitHub do reposit√≥rio.
2. Adicione o secret `ENABLE_SQLITE_CI` com valor `true` (opcional ‚Äî voc√™ tamb√©m pode disparar o workflow manualmente via Actions ‚Üí SQLite CI ‚Üí Run workflow).

O que o workflow faz:

- Instala ferramentas do sistema necess√°rias para compilar m√≥dulos nativos (build-essential, python3, libsqlite3-dev, cmake).
- Executa `npm ci` e compila `better-sqlite3`.
- Executa a su√≠te de testes com a vari√°vel `USE_SQLITE_CACHE=1` para validar o uso do cache SQLite.

Cautelas:

- O build de depend√™ncias nativas pode falhar em runners sem toolchain (ex.: Windows self-hosted sem Visual Studio). Recomendo disparar manualmente na primeira vez e inspecionar logs.
- Se preferir armazenamento persistente do banco gerado, podemos estender o workflow para enviar o arquivo `.db` como artifact ou para um bucket S3.


Como usar (PowerShell):

```powershell
$env:BASE_URL_CAMARA = 'https://dadosabertos.camara.leg.br/api/v2'
$env:BASE_URL_SENADO = 'https://legis.senado.leg.br/dadosabertos'
# Se precisar de chave do Portal da Transpar√™ncia:
$env:PORTAL_KEY = '<SUA_CHAVE_AQUI>'

npm run test:integration
```

Nota: se voc√™ n√£o fornecer `PORTAL_KEY` ou outras chaves, alguns testes que demandam autentica√ß√£o v√£o emitir avisos ou retornar um erro esperado. Esses scripts servem como sanity checks r√°pidos.

### Rodando testes de integra√ß√£o localmente

1. Copie o arquivo `.env.example` para `.env` e preencha os valores (especialmente `PORTAL_API_KEY` quando dispon√≠vel):

```powershell
cp .env.example .env
# editar .env com um editor de texto e preencher os valores
```

1. No PowerShell, carregue as vari√°veis do `.env` e execute o runner de integra√ß√£o:

```powershell
# Windows PowerShell (pode usar um utilit√°rio como 'dotenv' ou set manually):
Get-Content .env | ForEach-Object { $parts = $_ -split '='; if ($parts[0]) { setx $parts[0] $parts[1] } }
# Depois abra um novo terminal para carregar as vari√°veis, ou defina temporariamente:
# $env:PORTAL_API_KEY = 'SUA_CHAVE_AQUI'

# Rodar o runner de integra√ß√£o que carrega `.env` automaticamente:
npm run test:integration:local
```

Observa√ß√£o: o script de integra√ß√£o tentar√° usar `PORTAL_API_KEY` e `PROXY_ADMIN_TOKEN` se presentes; caso contr√°rio, ele ir√° rodar os checks que n√£o requerem credenciais.

## Equipe

**Desenvolvimento**: Equipe dedicada √† transpar√™ncia pol√≠tica
**Design**: Especialistas em UX/UI

## Modo desenvolvedor (bot√£o de carregamento local)

Para facilitar desenvolvimento e testes locais h√° um bot√£o flutuante que permite carregar fixtures CSV manualmente.

- O bot√£o √© exibido automaticamente quando a aplica√ß√£o roda em `localhost` ou `127.0.0.1`.
- Para ativ√°-lo deliberadamente em qualquer ambiente voc√™ pode:
  - adicionar `?dev=1` √† URL (ex.: <http://seu-host:8000/?dev=1>), ou
  - habilitar via console do navegador: `localStorage.setItem('DEV_LOAD','1')` e recarregar a p√°gina.

Observa√ß√£o: em ambientes que n√£o sejam localhost, o bot√£o N√ÉO ser√° exibido a menos que uma das flags acima esteja presente.

**Dados**: Analistas pol√≠ticos e cientistas de dados
**Revis√£o**: Especialistas em direito e pol√≠tica

## Licen√ßa

Este projeto √© licenciado sob a MIT License - veja o arquivo LICENSE para detalhes.

## Agradecimentos

- Congresso Nacional por disponibilizar dados p√∫blicos
- Comunidade open source pelas ferramentas utilizadas
- Volunt√°rios que contribuem com o projeto
- Cidad√£os brasileiros que acreditam na transpar√™ncia

---

**Pol√≠tica Transparente Brasil** - Fortalecendo a democracia atrav√©s da informa√ß√£o. üáßüá∑

## Como rodar localmente

Existem duas formas simples de rodar o projeto localmente na porta 8000.

1. Usando Python (j√° testado neste ambiente)

No PowerShell, execute:

```powershell
Set-Location -LiteralPath 'h:\TransparenciaPolitica'
python -m http.server 8000
```

Depois abra no navegador: <http://localhost:8000>

1. Usando npm (quando voc√™ preferir n√£o depender do Python)

O reposit√≥rio inclui um script alternativo que usa `npx http-server`.

No PowerShell, execute:

```powershell
Set-Location -LiteralPath 'h:\TransparenciaPolitica'
npm install --no-audit --no-fund
npm run dev:npm
```

Isto usa `npx http-server -p 8000` e serve os arquivos est√°ticos na mesma porta.

Parar o servidor Python (se em background):

```powershell
Get-Process -Name python | Stop-Process
```

## Proxy local e fallback CSV

O projeto pode integrar o Portal da Transpar√™ncia sem expor a chave API no navegador.

- Rodar o proxy local (insere a chave do Portal nas requisi√ß√µes server-side):

```powershell
Set-Location -LiteralPath 'h:\TransparenciaPolitica'
npm run start-proxy
```

- Definir a chave da API no proxy (opcionalmente com um token admin):

```powershell
# Exemplo: node scripts/post-proxy-key.js <SUA_CHAVE>
node scripts/post-proxy-key.js "SUA_CHAVE_AQUI"
```

- Remover a chave do proxy:

```powershell
node scripts/unset-proxy-key.js
```

- Fallback local (CSV): se voc√™ n√£o tiver a chave do Portal, pode baixar os dados p√∫blicos em CSV/ZIP e coloc√°-los em `resources/data/`.

O reposit√≥rio j√° inclui um downloader simples e alguns datasets baixados como exemplo:

```powershell
# Baixar manualmente com o script (exemplo):
node scripts/download_portal_datasets.js https://portaldatransparencia.gov.br/download-de-dados/despesas/20250101

# Os arquivos baixados s√£o salvos em resources/data/
```


- Exemplo de datasets j√° presentes em `resources/data/`:

  - `20250101_Despesas.zip` (extra√≠do em `resources/data/20250101_extracted/`)
  - `auxilio-brasil.csv`
  - `auxilio-emergencial.csv`
  - `auxilio-reconstrucao.csv`
  - `bolsa-familia-pagamentos.csv`
  - `bolsa-familia-saques.csv`
  - `novo-bolsa-familia.csv`

Integra√ß√£o com o app:

- Para usar esses CSVs localmente no app, voc√™ pode arrastar e soltar ou usar o input de upload dispon√≠vel no rodap√© (quando implementado), ou copiar um CSV para `resources/data/` e chamar `window.governmentAPI.loadDespesasFromCSV()` via console para popular o fallback local (`governmentAPI.useLocalDespesas(...)`).

Se quiser, eu posso:

1. Integrar automaticamente os CSVs de `resources/data/` ao build (copi√°-los para `dist/resources/data/`) e adicionar um pequeno carregador que detecta e registra automaticamente os arquivos encontrados.
2. Adicionar documenta√ß√£o passo-a-passo com capturas de tela e exemplos de uso no navegador.

## Testes

Executar os testes unit√°rios (Jest):

```powershell
npm run test:unit
```

Smoke test do parser (r√°pido):

```powershell
npm test
```

## P√°gina Admin

Ap√≥s `npm run build` e `npm run preview`, abra `http://localhost:8000/admin.html` para pr√©-visualizar datasets no `dist/resources/data/` e carregar um dataset no app aberto em outra aba.
Se quiser, eu posso tamb√©m adicionar um pequeno script `npm ci`/`start` mais completo ou configurar um arquivo `serve.json` para `http-server`.

